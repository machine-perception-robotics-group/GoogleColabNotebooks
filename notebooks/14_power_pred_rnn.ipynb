{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"14_power_pred_rnn.ipynb","provenance":[{"file_id":"https://github.com/machine-perception-robotics-group/GoogleColabNotebooks/blob/master/notebooks/14_power_pred_rnn.ipynb","timestamp":1613463831588}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"id":"W2tEwyj55RY3"},"source":["# Recurrent Neural Networkによる電力予測\n","\n","\n","---\n","## 目的\n","Recurrent Neural Networkを使って電力予測を行う．ここで，今回はRecurrent Neural Networkの一種である，Long Short Term Memory（LSTM）を使用する．\n","また，PyTorchで使用されるデータセットオブジェクトの作成を行う．"]},{"cell_type":"markdown","metadata":{"id":"Xo4jjpmwvle1"},"source":["## モジュールのインポート\n","はじめに必要なモジュールをインポートする．\n"]},{"cell_type":"code","metadata":{"id":"iCeaCulfvlao"},"source":["from time import time\n","from os import path\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","\n","# GPUの確認\n","use_cuda = torch.cuda.is_available()\n","print('Use CUDA:', use_cuda)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rQGfxWYK_4O"},"source":["### データのダウンロード\n","プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．"]},{"cell_type":"code","metadata":{"id":"Spzsxbxq5Req"},"source":["!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/SOLAR/data.zip\n","!unzip -q data.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uldeLCrV5RiN"},"source":["## データセットオブジェクトの作成\n","\n","電力データセットに対する，PyTorchのデータセットオブジェクト (`torch.utils.data.Dataset`) を作成します．\n","`Dataset`は，指定したデータセットを読み込み，学習やテストのためにデータを準備し生成するためのクラスです．\n","これまでの実習で使用したMNISTやCIFARデータセットはPyTorch (torchvision) 内に準備されているデータセットオブジェクトでした．\n","今回用いるデータセットは，torchvisonには存在しないため，自身で定義を行います．\n","\n","まず，`__init__`関数により，必要なデータを読み込みます．\n","この時，`__init__`関数の引数を指定します．\n","`root`は読み込むデータセットを配置しているディレクトリ，`train`は学習またはテストデータのどちらを扱うかを指定する変数，`delay`は入力された情報の何時刻後を正解として用意するかを指定する変数，`time_window`は1サンプルあたり何時刻のデータを準備するかをしてする変数です．\n","\n","まず，`root`および`train`変数から，学習またはテストデータを読み込みます．\n","その後，`delay`で指定した時刻を元に正解データを準備します．\n","最後に，`time_window`で指定した時間窓で1サンプルとなるように，データを作成し，`self.data`および`self.label`にデータを格納します．\n","これにより，`self.data`，`self.label`に入力データおよび正解データを格納します．\n","\n","`__getitem__`関数で，指定したインデックス（`item`）のデータを取り出し，返します．\n","\n","`__len__`関数は，このデータセットが保有するサンプル数を返すように定義を行います．"]},{"cell_type":"code","metadata":{"id":"PnxDTzWG5Rmk"},"source":["class BEMSDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, root=\"./data\", train=True, delay=1, time_window=10):\n","        super().__init__()\n","        self.root = root\n","        self.train = train\n","        self.delay = delay\n","        self.time_window = time_window\n","\n","        # データの読み込み\n","        if self.train:\n","            data_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_data.npy'))\n","            label_src = np.load(path.join(self.root, 'train', 'BEMS_RNN_train_labels.npy'))\n","        else:\n","            data_src  = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_data.npy'))\n","            label_src = np.load(path.join(self.root, 'test', 'BEMS_RNN_test_labels.npy'))\n","\n","        data_src = np.asarray(data_src[:-self.delay])\n","        label_src = np.asarray(label_src[self.delay:])\n","\n","        self.data = []\n","        self.label = []\n","        for frame_i in range(len(data_src) - self.time_window):\n","            self.data.append(data_src[frame_i:frame_i+self.time_window])\n","            self.label.append(label_src[frame_i:frame_i+self.time_window])\n","\n","        self.data = np.asarray(self.data)\n","        self.label = np.asarray(self.label)\n","\n","    def __getitem__(self, item):\n","        d = self.data[item, :]\n","        l = self.label[item, :]\n","        return d, l\n","\n","    def __len__(self):\n","        return self.data.shape[0]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SvGpadvk5RqS"},"source":["## ネットワークモデルの定義\n","再帰型ニューラルネットワークを定義します．\n","ここでは，LSTM層1層，全結合層1層から構成されるネットワークとします．\n","\n","LSTM層はRecurrent Neural Networkの一種です．\n","LSTMへの入力サイズはNoneとし，データにより変更できるようにしておきます．\n","\n","`forward`関数では，定義した層を接続して処理するように記述します．\n","この時，全結合層から出力された値はシグモイド関数へと入力され，最終的な出力結果をえます．\n","その後，mean_squared_error関数へ出力値と正解データを入力することで，誤差を計算します．誤差とネットワークの出力値の両方をreturnによって返しています．\n","\n","また，LSTMをはじめとするRecurrent Neural Networkでは，内部に過去の入力情報から計算した値を保持しています．"]},{"cell_type":"code","metadata":{"id":"9yXFXGSa5RuT"},"source":["class LSTM(nn.Module):\n","    def __init__(self, n_hidden):\n","        super(LSTM, self).__init__()\n","        self.lstm = nn.LSTMCell(34, n_hidden)\n","        self.l1 = nn.Linear(n_hidden, 1)\n","        self.sigmoid = nn.Sigmoid()\n","    \n","    def forward(self, x, hx, cx):\n","        hx, cx = self.lstm(x, (hx, cx))\n","        h = self.sigmoid(hx)\n","        h = self.l1(h)\n","        return h, hx, cx"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhw3p5bt5Ryh"},"source":["## ネットワークの作成\n","上のプログラムで定義したネットワークを作成します．\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Iw8xkuhH5R3T"},"source":["n_hidden = 128\n","\n","model = LSTM(n_hidden)\n","if use_cuda:\n","    model.cuda()\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIM8XOcn_ver"},"source":["## 学習\n","先ほど定義したデータセットと作成したネットワークを用いて，学習を行います．\n","\n","1回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を10とします．\n","また，1サンプルあたりのデータの長さ（time window）を10に指定します．\n","\n","次にデータローダーを定義します．\n","データローダーでは，上で読み込んだデータセット（`train_data`）を用いて，for文で指定したミニバッチサイズでデータを読み込むオブジェクトを作成します．\n","この時，`shuffle=True`と設定することで，読み込むデータを毎回ランダムに指定します．\n","\n","次に，誤差関数を設定します．\n","今回は，連続値を出力する回帰問題をあつかうため，`MSELoss`を`criterion`として定義します．\n","\n","学習を開始します．\n","\n","各更新において，学習用データと教師データをそれぞれ`data`と`label`とします．\n","まず，LSTMの隠れ状態とセル状態である`hx`と`cx`を`torch.zeros`を用いて初期化します．\n","この時，1次元目のサイズはバッチサイズに対応するように，`data`のサイズから自動的に決定します．\n","\n","その後，学習モデルに`data`を与えて各クラスの確率yを取得します．\n","今回はLSTMを用いて時系列データを順次処理するため，for文を用いて，各時刻のデータを順番に入力し，結果を得ます．\n","そして，各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n","また，認識精度も算出します．\n","そして，誤差をbackward関数で逆伝播し，ネットワークの更新を行います．"]},{"cell_type":"code","metadata":{"id":"2YKmAy2y_vi5"},"source":["# ミニバッチサイズ・エポック数の設定\n","batch_size = 100\n","epoch_num = 30\n","time_window = 10\n","\n","# データセットの読み込み・データローダーの設定\n","train_data = BEMSDataset(root=\"./data\", train=True, delay=1, time_window=time_window)\n","train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","\n","# 誤差関数の設定\n","criterion = nn.MSELoss()\n","if use_cuda:\n","    criterion.cuda()\n","\n","# ネットワークを学習モードへ変更\n","model.train()\n","\n","start = time()\n","for epoch in range(1, epoch_num+1):\n","    total_loss = 0\n","\n","    for data, label in train_loader:\n","        hx = torch.zeros(data.size()[1], n_hidden)\n","        cx = torch.zeros(data.size()[1], n_hidden)\n","        \n","        if use_cuda:\n","            data = data.cuda()\n","            label = label.cuda()\n","            hx = hx.cuda()\n","            cx = cx.cuda()\n","        \n","        for idx_window in range(time_window):\n","            y, hx, cx = model(data[idx_window], hx, cx)\n","            loss = criterion(y, label[idx_window])\n","            total_loss += loss.item()\n","            \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","  \n","    elapsed_time = time() - start\n","    print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, total_loss, elapsed_time))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ll0rYcEf_vma"},"source":["## テスト\n","学習したネットワークモデルを用いて評価（予測結果の可視化）を行います．\n","可視化にはmatplotlibを用います"]},{"cell_type":"code","metadata":{"id":"2RxKzGki_vqR"},"source":["# データセットの読み込み・データローダーの設定\n","test_data = BEMSDataset(root=\"./data\", train=False, delay=1, time_window=1)\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n","\n","# ネットワークを評価モードへ変更\n","model.eval()\n","\n","prediction_result = []\n","        \n","# 評価の実行\n","hx = torch.zeros(1, n_hidden)\n","cx = torch.zeros(1, n_hidden)\n","if use_cuda:\n","    hx = hx.cuda()\n","    cx = cx.cuda()\n","    \n","with torch.no_grad():\n","    for data, label in test_loader:\n","        \n","        if use_cuda:\n","            data = data.cuda()\n","\n","        y, hx, cx = model(data[0], hx, cx)\n","        \n","        prediction_result.append(y.item())\n","\n","prediction_result = np.array(prediction_result).flatten()\n","\n","\n","# 結果の表示\n","plt.figure()\n","plt.plot(test_data.label, color='red', label='true')\n","plt.plot(prediction_result.tolist(), color='blue', label='pred')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQx_GrVmBaui"},"source":[""],"execution_count":null,"outputs":[]}]}