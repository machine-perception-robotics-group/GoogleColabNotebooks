{"cells":[{"cell_type":"markdown","metadata":{"id":"X6widSYB2qPy"},"source":["# 非線形SVMによる教師あり学習\n","\n","\n","---\n","## 目的\n","非線形SVM(Support Vector Machine)を用いて2つのサンプルを識別する．その後，交差検定法を用いて識別テストを行う．\n","\n","\n","## プログラムの動作\n","下記のプログラムを実行すると，`data/car.txt`と`data/human.txt`の2つ読み込む．次に，非線形SVMによる学習およびテストを交差検定法を用いて行う．最後に，識別率とグラフを表示する．\n","\n","\n","## プログラムの解説\n","プログラムを上から順番に解説していく．なお，今回は第5回と同じプログラムで識別器の定義を変更しただけであるため，細かい説明は省略する．わからないところがあれば第5回の解説を読み返すこと．様々な識別器を簡単に切り替えて使うことができるのもscikit-learnの利点である．"]},{"cell_type":"markdown","metadata":{"id":"JP_F0BXzGDZY"},"source":["## 準備\n","プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍する．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5VPyTivFe9DM"},"outputs":[],"source":["import gdown\n","gdown.download('https://drive.google.com/uc?id=1Li0sdp2loJ7rcZjtzIx7uGG3r6Vs62TO', 'car_human_data.zip', quiet=False)\n","!unzip -q -o car_human_data.zip\n","!mv car_human_data data\n","!ls -R ./data"]},{"cell_type":"markdown","metadata":{"id":"nse8nIbg3kSl"},"source":["## モジュールのインポート\n","初めに，必要なモジュールをインポートする．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKGS7Dg93kdB"},"outputs":[],"source":["from os import path\n","import numpy as np\n","from sklearn import svm\n","from sklearn import metrics\n","from sklearn import model_selection"]},{"cell_type":"markdown","metadata":{"id":"0UYMZ3_73kkx"},"source":["## データの読み込み\n","次に，テキストファイルを読み込む．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTgQRWfX3kt9"},"outputs":[],"source":["in_txt1 = open(path.join('data', 'car.txt'))\n","in_txt2 = open(path.join('data', 'human.txt'))\n","\n","car = np.asarray([(line.strip()).split('\\t') for line in in_txt1], dtype=float)\n","print(car.shape)\n","human = np.asarray([(line.strip()).split('\\t') for line in in_txt2], dtype=float)\n","print(human.shape)"]},{"cell_type":"markdown","metadata":{"id":"GILINiVW3k3f"},"source":["## データのラベル付けと結合，交差検定法の準備\n","学習を行う前に，データがcarまたはhumanどちらのクラスに属するかラベル付けをする．また，交差検定法に使うオブジェクトを準備する．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GX4Jjyk23lCr"},"outputs":[],"source":["car_y =  np.zeros(car.shape[0])\n","human_y = np.ones(human.shape[0])\n","X= np.r_[car, human]\n","y= np.r_[car_y, human_y]\n","\n","kfold = model_selection.KFold(n_splits=5, shuffle=True, random_state=0)\n","print(X.shape, y.shape)"]},{"cell_type":"markdown","metadata":{"id":"qjXfrTQf3lMZ"},"source":["## 学習と評価\n","for文で学習と評価をk回繰り返す．\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TavnRYpT3lVD"},"outputs":[],"source":["scores = []\n","best_score = 0.0\n","\n","for train, test in kfold.split(X):\n","    classifier = svm.SVC(C=2**12, kernel='rbf', gamma=2**-20, random_state=0)\n","    classifier.fit(X[train], y[train])\n","    preds = classifier.predict(X[test])\n","    score = metrics.accuracy_score(preds, y[test])\n","    scores.append(score)\n","\n","    if score > best_score:\n","        best_classifier = classifier\n","        best_score = score"]},{"cell_type":"markdown","metadata":{"id":"GdedAEIs3lc9"},"source":["`classifier = svm.SVC(C=2**12, kernel='rbf', gamma=2**-20)`が識別器の定義となる．今回はlinearでないSVCとなる．主なパラメータとして`C`と`kernel`と`gamma`がある．\n","\n","- `C`: 誤分類に対するペナルティ\n","- `kernel`: 利用するカーネル関数\n","- `gamma`: rbfカーネルを用いたときのガンマの値\n","\n","カーネル関数とガンマについては後述する．直感的には，`C`は誤分類を厳しくチェックするかを決め，`gamma`はどれくらい複雑な曲線でクラスを分類するかを決める．これらのパラメータの値はうまく調整しなければならない．単に値を高くしておくだけではうまく識別できない．\n","\n","### カーネル法\n","非線形のSVMは「カーネル法」と呼ばれる手法を用いる．この手法は，線形分離できない特徴点を線形分離可能な別の特徴空間に変換し，そこで線形分離を行い，最後に元の次元に戻すことで識別する．今回用いるrbfカーネル関数は次の式で表すことができる："]},{"cell_type":"markdown","metadata":{"id":"0vqCJ2ufFDPK"},"source":["## 識別率の計算\n","得られたk個の結果を平均して，識別率を求める．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PI1VxeJt3lj_"},"outputs":[],"source":["accuracy = (sum(scores) / len(scores)) * 100\n","msg = 'recognition rate: {accuracy:.2f}%'.format(accuracy=accuracy)\n","print(msg)"]},{"cell_type":"markdown","metadata":{"id":"fqlE8I_eFIm3"},"source":["## グラフの描画\n","識別結果を可視化するためにグラフを作成する．どちらのクラスがどの領域かわかりやすく表示することができる．\n","\n","曲線で2つの領域が分けられていることがわかる．"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hst-_iOH3g5M"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","fig = plt.figure()\n","subfig = fig.add_subplot(1,1,1)\n","plt.xlim(0, 10000)\n","plt.ylim(20, 50)\n","\n","xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 500),\n","                     np.linspace(plt.ylim()[0], plt.ylim()[1], 500))\n","\n","Z = best_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n","\n","subfig.scatter(car[:,0], car[:,1],color='black')\n","subfig.scatter(human[:,0], human[:,1],color='red')\n","\n","subfig.set_title('Feature Distribution')\n","subfig.set_xlabel('Area')\n","subfig.set_ylabel('complexity')\n","\n","plt.savefig(\"06_graph.png\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"dhFULf8yFXXq"},"source":["## 課題\n","1. `gamma`の値を大きくするとどうなるか．グラフで確認せよ．\n","2. 識別率の最も高くなるパラメータを探せ．\n","\n","\n","## ヒント\n","1. `gamma=2**-10`(2のマイナス10乗)〜`gamma=2**-15`(2のマイナス15乗)あたりがわかりやすい．これがいわゆる「過学習（Over Fitting）」状態である．\n","2. パラメータを小さく変更していくと良い．「グリッドサーチ」が導入できると尚良い．興味のある人は調べてみること．\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"06_nonliear_svm.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
