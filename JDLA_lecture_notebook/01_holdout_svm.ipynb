{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ホールドアウト法によるサポートベクトルマシンの性能評価\n",
    "\n",
    "---\n",
    "## 目的\n",
    "ホールドアウト法を用いて，サポートベクトルマシン（Support Vector Machine; SVM）の性能を評価する．\n",
    "また，テキストファイルの読み込みやNumpyモジュールを使用した，データセットの読み込み・整理を行う．\n",
    "\n",
    "## 対応するチャプター\n",
    "* 5.3: ホールドアウト法\n",
    "* 5.7: サポートベクトルマシン\n",
    "\n",
    "## データセットのダウンロード\n",
    "プログラムの動作に必要なデータをダウンロードし，zipファイルを解凍します．\n",
    "zipファイルを解凍すると,`./data`ディレクトリの中に`car.txt`と`human.txt`の2つのテキストファイルが保存されています．\n",
    "下記のプログラムでは，これらのテキストファイルを読み込み，実験に使用します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q http://www.mprg.cs.chubu.ac.jp/tutorial/ML_Lecture/sklearn/data.zip -O data.zip\n",
    "!unzip -q -o data.zip\n",
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モジュールのインポート\n",
    "プログラムの実行に必要なモジュールをインポートします．\n",
    "実験にはNumpyとPythonの機械学習用ライブラリである，scikit-learnを使用します．\n",
    "使用するクラス，関数は以下の通りです．\n",
    "* `numpy`は配列を扱うためのライブラリ\n",
    "* `matplotlib`はグラフを描画するためのライブラリ\n",
    "* `LinearSVC`はサポートベクトルマシンを使用するためのクラス\n",
    "* `train_test_split`はデータを学習用とテスト用のデータに分割するための関数\n",
    "* `accuracy_score`は認識率を計算するための関数です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "上でダウンロード・解凍したファイルを読み込みます．\n",
    "Pythonには「リスト」と言う配列に似たものが標準で実装されていますが，\n",
    "今回はNumpyを利用してデータを読み込みます．\n",
    "\n",
    "### テキストファイルの読み込み\n",
    "まず，`open()`関数を使用して，テキストファイルをPython上で読み込みます．\n",
    "\n",
    "### Numpy array（配列）へ格納\n",
    "次に，ファイルの中身を参照して配列に入れます．\n",
    "\n",
    "まず，読み込んだデータを一時的に保存するためのリスト (`car` or `human`) を作成します．\n",
    "\n",
    "そして，`for line in in_txt1:`のfor文によって，テキストファイルを1行ずつ読み込んで処理を実行します．\n",
    "このfor文では，「`in_txt1`の中身を変数`line`に1行ずつ入れて実行」というループを実行しています．\n",
    "このfor文の書き方はPython特有の書き方です．\n",
    "\n",
    "続いて，`(line.strip()).split('\\t')`の`line.strip()`は「文字列変数`line`から空白文字や改行コードを取り除く」という処理です．\n",
    "これを行わずに処理を行うと，変数`line`に残っている改行コードが一緒に処理されてしまうため，変数やリストに改行コードが入ってしまうことになり注意が必要です．\n",
    "さらに続けて`.split('\\t')`と記述することにより，先程得られた改行コードのない文字列を「指定された文字列で区切る」という処理を行います．\n",
    "ここでは`'\\t'`つまりタブが指定されているため，タブで区切ります．\n",
    "例えば，`1512.000000 (タブ) 26.779374`という文字列があったとき，この処理を行うことで`['1512.000000', '26.779374']`というリストが生成されます．\n",
    "\n",
    "最後に，for文を抜けた後に，`np.asarray()`関数を用いて，リストに格納した数値データをnumpyの配列に変換しています．\n",
    "\n",
    "#### 補足：リスト内包表記\n",
    "上記の一連の処理を，1行で記述することができる．\n",
    "このような書き方を「リスト内包表記」と呼び，リストを生成する際によく用いられる．\n",
    "```\n",
    "car = np.asarray([(line.strip()).split('\\t') for line in in_txt1], dtype=float)\n",
    "human = np.asarray([(line.strip()).split('\\t') for line in in_txt2], dtype=float)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストファイルの読み込み\n",
    "in_txt1 = open('./data/car.txt')\n",
    "in_txt2 = open('./data/human.txt')\n",
    "\n",
    "\n",
    "# Numpy arrayへ格納\n",
    "car = []\n",
    "for line in in_txt1:\n",
    "    car.append((line.strip()).split('\\t'))\n",
    "car = np.asarray(car, dtype=float)\n",
    "\n",
    "human = []\n",
    "for line in in_txt2:\n",
    "    human.append((line.strip()).split('\\t'))\n",
    "human = np.asarray(human, dtype=float)\n",
    "\n",
    "\n",
    "# 格納したデータの配列サイズを確認\n",
    "print(car.shape)\n",
    "print(human.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データのラベル付けと結合\n",
    "学習を行う前に各データがcarまたはhumanどちらのクラスに属するかラベル付けをする必要があります．\n",
    "ここでは，carのラベルを0，humanのラベルを1として，教師ラベルを作成します．\n",
    "また，この後の処理のために，carとhumanの配列を1つの配列に結合する．\n",
    "\n",
    "### ラベル付け\n",
    "`np.zeros`と`np.ones`はそれぞれnumpyの関数です．\n",
    "`zeros`は指定された数だけ要素を持った配列を用意する関数です．この時，配列の中身は全て0になります．\n",
    "`ones`は配列の中身は全て1になります．\n",
    "\n",
    "`car_y`にはcarのデータ数と同じ要素数の0配列が，`human_y`にはhumanと同じ要素数の1配列が生成されます．\n",
    "\n",
    "\n",
    "### データの結合\n",
    "データと教師ラベルを結合しますに\n",
    "結合には，`np.r_[]`関数を使用します．\n",
    "この関数は，与えられた2つ以上の配列を1つの配列として結合します．\n",
    "`x = np.r_[car, human]`の場合，配列`car`と`human`を1つの配列`x`として作成します．\n",
    "\n",
    "最終的に，carとhumanのデータが入った配列`x`と，そのラベルが入った配列`y`が作成されます．\n",
    "`x`のn番目の要素がどちらのクラスに属するかは配列`y`のn番目の要素を確認すればわかるということになります．\n",
    "\n",
    "![array.png](https://qiita-image-store.s3.amazonaws.com/0/143078/6cbc837a-d3a4-b953-683e-520052288ffd.png)\n",
    "\n",
    "\n",
    "確認のため，最後に`print(x.shape, y.shape)`で各配列の要素数を出力します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル付け\n",
    "car_y = np.zeros(car.shape[0])\n",
    "human_y = np.ones(human.shape[0])\n",
    "\n",
    "# 結合\n",
    "x = np.r_[car, human]\n",
    "y = np.r_[car_y, human_y]\n",
    "\n",
    "# 結合したデータの配列サイズを確認\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分割\n",
    "上記で読み込み・作成したデータを学習用データとテストデータに分割します．\n",
    "\n",
    "データの分割には`train_test_split`関数を使用します．\n",
    "はじめに`test_sample_ratio`でテストに用いるデータ数の割合を指定します．\n",
    "その後，`train_test_split`関数を用いて指定した割合でデータを分割します．\n",
    "`random_state`はデータをランダムに分割する際のseedです．\n",
    "seedを変更，または指定しないことで，無作為にデータを分割することが可能です．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの割合を指定\n",
    "test_sample_ratio = 0.3\n",
    "\n",
    "# データを分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_sample_ratio, random_state=0)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMの学習\n",
    "分割した学習用データでSVMを学習し，テストデータで学習したSVMの識別性能を評価します．\n",
    "\n",
    "まず，`LinearSVC`クラスを実行することでSVMを実行するための準備をします．\n",
    "`C`はSVMの学習時に用いられるパラメータ (ペナルティパラメータ) です．\n",
    "\n",
    "その後，`fit`関数を用いることでSVMの学習を実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVMの準備\n",
    "classifier = LinearSVC(C=1.0, random_state=0)\n",
    "\n",
    "# 学習\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMの評価\n",
    "学習したSVMでテストデータを識別することで，性能の確認を行います．\n",
    "\n",
    "`predict`関数を実行することで，関数に入力したデータの識別結果を出力します．\n",
    "\n",
    "その後，`accuracy_score`関数を用いることで，識別したクラスと教師ラベルから認識率を算出します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "pred_train = classifier.predict(x_train)\n",
    "pred_test = classifier.predict(x_test)\n",
    "\n",
    "score_train = accuracy_score(pred_train, y_train)\n",
    "score_test = accuracy_score(pred_test, y_test)\n",
    "\n",
    "print(\"train accuracy:\", score_train)\n",
    "print(\"test accuracy:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グラフの描画\n",
    "識別結果を可視化するために，学習した識別器を用いてグラフを作成する．\n",
    "どちらのクラスがどの領域かわかりやすく表示することができる．\n",
    "\n",
    "ここでは`meshgrid`を用いることで，指定した領域を格子状に分割し，その各格子の中心座標を`xx`と`yy`に保存している．\n",
    "その保存した座標を`classifier.predict()`関数に入力することで，各座標がどちらのクラスに属するかを求めている．\n",
    "各座標が属するクラスに従って塗りつぶすことで各クラスに属する領域（境界線）を描画している．\n",
    "塗りつぶしには`contourf`を用いている．\n",
    "\n",
    "最後に`scatter`関数を用いて，carおよびhumanクラスのデータを散布図としてプロットしている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作図領域の設定\n",
    "fig = plt.figure()\n",
    "subfig = fig.add_subplot(1,1,1)\n",
    "plt.xlim(0, 10000)\n",
    "plt.ylim(20, 50)\n",
    "\n",
    "# 格子点の作成\n",
    "xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 500),\n",
    "                     np.linspace(plt.ylim()[0], plt.ylim()[1], 500))\n",
    "\n",
    "# 格子点座標のクラス識別と塗りつぶし\n",
    "Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# データのプロット（散布図）\n",
    "subfig.scatter(car[:,0], car[:,1],color='black')\n",
    "subfig.scatter(human[:,0], human[:,1],color='red')\n",
    "\n",
    "# 軸ラベルの設定\n",
    "subfig.set_title('Support Vector Machine')\n",
    "subfig.set_xlabel('Area')\n",
    "subfig.set_ylabel('complexity')\n",
    "\n",
    "# 表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題\n",
    "以下の課題に取り組みましょう．\n",
    "\n",
    "1. ホールドアウト法によって分割する学習・テストデータの割合を変更して，認識率の変化を確認してみましょう．\n",
    "2. SVMのパラメータ`C`を変更して，認識率の変化を確認してみましょう．"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
