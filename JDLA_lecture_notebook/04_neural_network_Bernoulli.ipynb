{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ニューラルネットワークによる2クラス分類\n",
    "\n",
    "---\n",
    "## 目的\n",
    "多層パーセプトロン（Multi Layer Perceptron; MLP）を用いて，乳癌データの2クラス分類を行う．\n",
    "\n",
    "## 対応するチャプター\n",
    "* 6.2.2: ベルヌーイ分布出力のためのシグモイドユニット\n",
    "* 8.1.3: バッチアルゴリズムとミニバッチアルゴリズム\n",
    "* 8.3.1: 確率的勾配降下法\n",
    "\n",
    "## モジュールのインポート\n",
    "プログラムの実行に必要なモジュールをインポートします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットの読み込み\n",
    "実験に使用するデータセットを読み込みます．\n",
    "\n",
    "今回は**Breast Cancer Wisconsin Dataset**を用いて2クラス分類を行います．\n",
    "breast cancer datasetは乳癌のデータセットであり，クラス数は悪性腫瘍 (malignant)と良性腫瘍 (benign) の2クラス，データ数は569（悪性腫瘍 (malignant): 220, 良性腫瘍 (benign): 357）のデータセットです．\n",
    "各データは細胞核の半径や面積，テクスチャ情報を表現した30次元のベクトルデータです．\n",
    "\n",
    "[Breast Cancer Wisconsin (Diagnostic) Data Set](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))\n",
    "\n",
    "はじめに，`wget`コマンドを使用して，データセットのファイルをダウンロードします．\n",
    "\n",
    "次に，データと正解ラベルが含まれている`breast_cancer.csv`を読み込みます．\n",
    "読み込んだデータのうち，最初の30列に各データを表現した30次元のベクトルデータが格納されており，最後の1列に正解ラベル`(0, 1)`が格納されています．これらをそれぞれ，`x`と`y`に分割して格納します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットのダウンロード\n",
    "!wget -q http://www.mprg.cs.chubu.ac.jp/~hirakawa/share/tutorial_data/breast_cancer.csv -O breast_cancer.csv\n",
    "\n",
    "# データセットの読み込み\n",
    "breast_cancer_data = np.loadtxt(\"breast_cancer.csv\", dtype=np.float32, delimiter=\",\")\n",
    "x = breast_cancer_data[:, :-1]\n",
    "y = breast_cancer_data[:, -1].astype(np.int32)\n",
    "\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分割と正規化\n",
    "上記で読み込んだデータを学習用データとテストデータに分割し，正規化を行います．\n",
    "\n",
    "データの分割では，`test_sample_ratio`で，テストに用いるサンプルの割合を指定します．\n",
    "その後，データの総数から，学習とテストにするデータの数を算出し，ランダムにサンプルを振り分けます．\n",
    "このとき，`np.random.seed`はデータをランダムに分割する際のseedです．\n",
    "seedを変更，または指定しないことで，無作為にデータを分割することが可能です．\n",
    "\n",
    "次に正規化を行います．\n",
    "データ$x$の最小値を$x_{min}$，最大値を$x_{max}$としたとき，次の式で正規化を行います．\n",
    "$$x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "`np.min`と`np.max`で学習データの最大，最小値を取得し，上記の式に従い0~1の範囲に値を正規化します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "test_sample_ratio = 0.2  # テストデータの割合を指定\n",
    "num_data = x.shape[0]    # データの総数\n",
    "num_test = int(num_data * test_sample_ratio)\n",
    "num_train = num_data - num_test\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "random_index = np.random.permutation(num_data)\n",
    "x_train = x[random_index[0:num_train]]\n",
    "y_train = y[random_index[0:num_train]]\n",
    "x_test = x[random_index[num_train:]]\n",
    "y_test = y[random_index[num_train:]]\n",
    "\n",
    "# データの正規化\n",
    "x_min = np.min(x_train, axis=0)\n",
    "x_max = np.max(x_train, axis=0)\n",
    "\n",
    "x_train = (x_train[:, ] - x_min) / (x_max - x_min)\n",
    "x_test = (x_test[:, ] - x_min) / (x_max - x_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークモデルの定義\n",
    "次に，ニューラルネットワーク（多層パーセプトロン）を定義します．\n",
    "\n",
    "まずはじめに，ネットワークの定義に必要な関数を定義します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "def cross_entropy(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "\n",
    "def sigmod_cross_entropy(x, t):\n",
    "    y = sigmoid(x.flatten())\n",
    "    loss = - (t * np.log(y)) - ((1 - t) * np.log(1 - y))\n",
    "    return np.sum(loss)\n",
    "\n",
    "def binary_classification_accuracy(pred, true):\n",
    "    pred = pred.flatten()\n",
    "    clf_res = np.zeros(pred.shape, dtype=np.int32)\n",
    "    clf_res[pred > 0.5] = 1\n",
    "    return np.sum(clf_res == true).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上で定義した関数を用いてネットワークモデルを作成します．\n",
    "ここでは，入力層，中間層，出力層から構成される多層パーセプトロンを定義します．\n",
    "\n",
    "入力層と中間層のユニット数は引数として与え，それぞれ`input_size`，`hidden_size`とします．\n",
    "出力層サイズについては，今回は2クラス分類問題を扱うため，`0~1`でどちらのクラスに属するかを表現するように，ユニット数は1に固定します．\n",
    "そして，`__init__`関数を用いて，ネットワークのパラメータを初期化します．\n",
    "`w1`および`w2`は各層の重みで，`b1`および`b2`はバイアスを表しています．\n",
    "重みは`randn`関数で，標準正規分布に従った乱数で生成した値を保有する配列を生成します．\n",
    "バイアスは`zeros`関数を用いて，要素が全て0の配列を生成します．\n",
    "\n",
    "そして，`forward`関数で，データを入力して結果を出力するための演算を定義します．\n",
    "\n",
    "次に，`backward`関数ではパラメータの更新量を計算します．\n",
    "まず，ネットワークの出力結果と教師ラベルから，誤差`dy`を算出します．\n",
    "その後，連鎖律に基づいて，出力層から順番に勾配を計算していきます．\n",
    "このとき，パラメータの更新量を`self.grads`へ保存しておきます．\n",
    "\n",
    "最後に`update_parameters`関数で，更新量をもとにパラメータの更新を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPBernoulli:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, w_std=0.01):\n",
    "        self.w1 = w_std * np.random.randn(input_size, hidden_size)\n",
    "        self.b1 = np.zeros(hidden_size)\n",
    "        self.w2 = w_std * np.random.randn(hidden_size, 1)\n",
    "        self.b2 = np.zeros(1)        \n",
    "        self.grads = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.h1 = np.dot(x, self.w1) + self.b1\n",
    "        self.h2 = sigmoid(self.h1)\n",
    "        self.h3 = np.dot(self.h2, self.w2) + self.b2\n",
    "        return self.h3\n",
    "\n",
    "    def backward(self, x, t):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        _ = self.forward(x)\n",
    "        y = sigmoid(self.h3)\n",
    "        \n",
    "        # backward\n",
    "        self.grads = {}\n",
    "        \n",
    "        dy = (y - t.reshape(-1, 1)) / batch_size\n",
    "        self.grads['w2'] = np.dot(self.h2.T, dy)\n",
    "        self.grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        d_h2 = np.dot(dy, self.w2.T)\n",
    "        d_h1 = sigmoid_grad(self.h1) * d_h2\n",
    "        self.grads['w1'] = np.dot(x.T, d_h1)\n",
    "        self.grads['b1'] = np.sum(d_h1, axis=0)\n",
    "        \n",
    "    def update_parameters(self, lr=0.1):\n",
    "        self.w1 -= lr * self.grads['w1']\n",
    "        self.b1 -= lr * self.grads['b1']\n",
    "        self.w2 -= lr * self.grads['w2']\n",
    "        self.b2 -= lr * self.grads['b2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの作成と学習の準備\n",
    "上のプログラムで定義したネットワークを作成します．\n",
    "\n",
    "\n",
    "まず，中間層と出力層のユニット数を定義します．\n",
    "ここでは，入力層のユニット数`input_size`を学習データの次元，中間層のユニット数`hidden_size`を128とします．\n",
    "\n",
    "各層のユニット数を`MLPBernoulli`クラスの引数として与え，ネットワークを作成します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = x.shape[1]\n",
    "hidden_size = 128\n",
    "model = MLPBernoulli(input_size=input_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "読み込んだbreast cancerデータセットと作成したネットワークを用いて，学習を行います．\n",
    "\n",
    "1回の誤差を算出するデータ数（ミニバッチサイズ）を10，学習エポック数を100とします．\n",
    "\n",
    "学習データは毎回ランダムに決定するため，numpyの`permutation`という関数を利用します．\n",
    "各更新において，学習用データと教師データをそれぞれ`x_batch`と`y_batch`とします．\n",
    "学習モデルに`x_batch`を与えて，`h`を取得します．\n",
    "その後，`h`にシグモイド関数を適用することで，各クラスに対する分類スコア`y_pred`を求めます．\n",
    "取得した`y_pred`は精度および誤差を算出するための関数へと入力され，値を保存します．\n",
    "そして，誤差を`backward`関数で逆伝播し，`update_parameters`でネットワークの更新を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_data = x_train.shape[0]\n",
    "batch_size = 10\n",
    "epoch_num = 100\n",
    "\n",
    "for epoch in range(1, epoch_num + 1):\n",
    "    \n",
    "    sum_accuracy = 0.0\n",
    "    sum_loss = 0.0\n",
    "    \n",
    "    perm = np.random.permutation(num_train_data)\n",
    "    for i in range(0, num_train_data, batch_size):\n",
    "        x_batch = x_train[perm[i:i+batch_size]]\n",
    "        y_batch = y_train[perm[i:i+batch_size]]\n",
    "        \n",
    "        h = model.forward(x_batch)\n",
    "        y_pred = sigmoid(h)\n",
    "        sum_accuracy += binary_classification_accuracy(y_pred, y_batch)\n",
    "        sum_loss += sigmod_cross_entropy(h, y_batch)\n",
    "        \n",
    "        model.backward(x_batch, y_batch)\n",
    "        model.update_parameters(lr=0.1)\n",
    "    \n",
    "    if epoch % 10 == 0:        \n",
    "        print(\"epoch: {}, mean loss: {}, mean accuracy: {}\".format(epoch,\n",
    "                                                                   sum_loss / num_train_data,\n",
    "                                                                   sum_accuracy / num_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テスト\n",
    "学習したネットワークを用いて，テストデータに対する認識率の確認を行います．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "num_test_data = x_test.shape[0]\n",
    "\n",
    "for i in range(num_test_data):\n",
    "    x = np.array([x_test[i]], dtype=np.float32)\n",
    "    t = y_test[i]\n",
    "    y = sigmoid(model.forward(x))\n",
    "    \n",
    "    if y[0, 0] > 0.5:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0\n",
    "    \n",
    "    if pred == t:\n",
    "        count += 1\n",
    "\n",
    "print(\"test accuracy: {}\".format(count / num_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
